{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # only potentially necessary if you have MacBook with M1/M2 chip\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy MNIST dataset\n",
    "class NoisyMNIST(Dataset):\n",
    "    # constructor\n",
    "    '''\n",
    "    train: (bool) True for training data, False for test/validation data\n",
    "    noise_strength: (float) variance (strength) of the additive noise, keep between [0, 0.5]\n",
    "    '''\n",
    "    def __init__(self, train, noise_strength):\n",
    "        mnist_data = torchvision.datasets.MNIST('./', train=train, download=True)\n",
    "        self.images = (mnist_data.data/255).float() # convert to [0, 1] range and make float\n",
    "        self.images = self.images.unsqueeze(1) # make shape (N_images, 1, H , W)\n",
    "        self.noise_strength = noise_strength\n",
    "        self.noise = torch.randn(self.images.shape)*self.noise_strength\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        noisy_image = torch.clip(self.images[idx]+self.noise[idx], min=0, max=1)\n",
    "        return noisy_image, self.images[idx].squeeze(0)\n",
    "\n",
    "# make training set\n",
    "noise_strength = 0.3\n",
    "noisy_mnist_training = NoisyMNIST(True, noise_strength)\n",
    "# make test set\n",
    "noisy_mnist_validation = NoisyMNIST(False, noise_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79440c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some (noisy, true image) pairs\n",
    "plt.figure(figsize=(12,6))\n",
    "for i in range(4):\n",
    "    idx = np.random.choice(np.arange(len(noisy_mnist_training)))\n",
    "    noisy_image, true_image = noisy_mnist_training[idx]\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(noisy_image.squeeze(0).numpy(), 'gray')\n",
    "    plt.axis(False)\n",
    "    plt.subplot(2, 4, i+5)\n",
    "    plt.imshow(true_image.squeeze(0).numpy(), 'gray')\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model code\n",
    "class Autoencoder(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, channel_widths, image_height, image_width, nonlinearity=nn.ReLU()):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        assert len(channel_widths) >= 2, \"channel_widths should be at least length-2\"\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        layers = []\n",
    "        # make encoder side\n",
    "        for i in range(len(channel_widths)-1):\n",
    "            layers.append(nn.Conv2d(channel_widths[i], channel_widths[i+1],\n",
    "                                    kernel_size=5, padding=2, stride=2, bias=False)) # conv layer\n",
    "            layers.append(nonlinearity) # non-linearity\n",
    "            \n",
    "        # make decoder side\n",
    "        for i in range(len(channel_widths)-1, 1, -1):\n",
    "            layers.append(nn.Conv2d(channel_widths[i], channel_widths[i-1],\n",
    "                                    kernel_size=5, padding=2, stride=1, bias=False)) # conv layer\n",
    "            layers.append(nn.Upsample(scale_factor=2, mode='nearest')) # upscale image by factor of 2\n",
    "            layers.append(nonlinearity)\n",
    "        # compose the encoder and decoder back-to-back\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        # make sure output matches size of input image\n",
    "        self.final_upsample = nn.Upsample(size=(self.image_height, self.image_width), mode='nearest')\n",
    "        # final convolution layer to give 1 output channel like the input image\n",
    "        # this layer also serves to provide the final estimate of the pixel values\n",
    "        self.final_conv = nn.Conv2d(channel_widths[1], 1,\n",
    "                                    kernel_size=5, padding=2, stride=1, bias=False)\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x) # get feature maps\n",
    "        resized_features = self.final_upsample(features) #(batch_size, N_feature_maps, H, W)\n",
    "        pixel_predictions = self.final_conv(resized_features) # (batch_size, 1, H, W)\n",
    "        pixel_predictions = pixel_predictions.squeeze(1) # batch_size, H, W\n",
    "        return pixel_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating autoencoder model\n",
    "channel_widths = [1, 8, 16] # must start with 1\n",
    "image_height, image_width = 28, 28\n",
    "model = Autoencoder(channel_widths, image_height, image_width)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, training_data, validation_data,\n",
    "          training_indices, validation_indices, config, verbose=False):\n",
    "    # unpack configuration parameters\n",
    "    lr = config['lr'] # learning rate\n",
    "    n_epochs = config['n_epochs'] # number of passes (epochs) through the training data\n",
    "    batch_size = config['batch_size']\n",
    "    \n",
    "    # set up optimizer and loss function\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    # set up dataloaders\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(training_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(validation_indices)\n",
    "    trainloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, sampler=train_sampler)\n",
    "    valloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    # training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for n in range(n_epochs):\n",
    "        # set model to training mode (unnecessary for this model, but good practice)\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, targets in trainloader:\n",
    "            optimizer.zero_grad() # zero out gradients\n",
    "            class_logits = model(images)\n",
    "            loss = criterion(class_logits, targets)\n",
    "            loss.backward() # backpropagate to compute gradients\n",
    "            optimizer.step() # update parameters using stochastic gradient descent\n",
    "            # update epoch statistics\n",
    "            epoch_loss += loss.item() # batch loss\n",
    "            \n",
    "        # validation\n",
    "        epoch_loss /= len(trainloader)\n",
    "        val_loss = validate(model, valloader, criterion)\n",
    "        val_loss /= len(valloader)\n",
    "        \n",
    "        # log epoch information\n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if verbose and (n+1) % (int(n_epochs/20)) == 0:\n",
    "            print('Epoch {}/{}: (Train) Loss = {:.4e}, (Val) Loss = {:.4e}'.format(\n",
    "                   n+1,\n",
    "                   n_epochs,\n",
    "                   epoch_loss,\n",
    "                   val_loss))\n",
    "        \n",
    "        \n",
    "    return (np.array(train_losses),\n",
    "            np.array(val_losses),\n",
    "            model)\n",
    "        \n",
    "def validate(model, dataloader, criterion):\n",
    "    val_loss = 0\n",
    "    # set model to eval mode (again, unnecessary here but good practice)\n",
    "    model.eval()\n",
    "    # don't compute gradients since we are not updating the model, saves a lot of computation\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            class_logits = model(images)\n",
    "            loss = criterion(class_logits, targets)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# make training set\n",
    "noise_strength = 0.2\n",
    "noisy_mnist_training = NoisyMNIST(True, noise_strength)\n",
    "# make test set\n",
    "noisy_mnist_validation = NoisyMNIST(False, noise_strength)\n",
    "# you can try playing around with more or less training data\n",
    "N_training_examples = 500\n",
    "N_validation_examples = 500\n",
    "random_seed = 1 # random seed for reproducibility\n",
    "np.random.seed(random_seed)\n",
    "training_indices = np.random.choice(np.arange(len(noisy_mnist_training)), size=N_training_examples)\n",
    "validation_indices = np.random.choice(np.arange(len(noisy_mnist_validation)), size=N_validation_examples)\n",
    "\n",
    "# configuration parameters, you can play around with these\n",
    "config = {'lr': 1e-1,\n",
    "          'n_epochs': 300,\n",
    "          'batch_size': 100}\n",
    "\n",
    "loss_function = 'mse' # mse (mean-square error) or mae (mean-absolute error)\n",
    "if loss_function == 'mse':\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "# model\n",
    "channel_widths = [1, 16, 16] # must start with a 1 and be at least length--2\n",
    "image_height, image_width = 28, 28\n",
    "model = Autoencoder(channel_widths, image_height, image_width)\n",
    "\n",
    "# train\n",
    "verbose = True # print metrics during training, False for no printing\n",
    "train_losses, val_losses, trained_model = train(model,\n",
    "                                                criterion,\n",
    "                                                noisy_mnist_training,\n",
    "                                                noisy_mnist_validation,\n",
    "                                                training_indices,\n",
    "                                                validation_indices,\n",
    "                                                config,\n",
    "                                                verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training/validation loss and accuracy over training time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.semilogy(train_losses, color='royalblue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training loss')\n",
    "plt.grid(True)\n",
    "plt.subplot(122)\n",
    "plt.semilogy(val_losses, color='royalblue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Validation loss')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some (noisy, true image, denoised image) results\n",
    "with torch.no_grad():\n",
    "    N = 5\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for i in range(N):\n",
    "        idx = np.random.choice(np.arange(len(noisy_mnist_training)))\n",
    "        noisy_image, true_image = noisy_mnist_training[idx]\n",
    "        denoised_image = model(noisy_image.unsqueeze(0)).squeeze(0)\n",
    "        plt.subplot(3, N, i+1)\n",
    "        plt.title('Noisy image')\n",
    "        plt.imshow(noisy_image.squeeze(0).numpy(), 'gray')\n",
    "        plt.axis(False)\n",
    "        plt.subplot(3, N, i+1+N)\n",
    "        plt.title('True image')\n",
    "        plt.imshow(true_image.squeeze(0).numpy(), 'gray')\n",
    "        plt.axis(False)\n",
    "        plt.subplot(3, N, i+1+2*N)\n",
    "        plt.title('De-noised image')\n",
    "        plt.imshow(denoised_image.squeeze(0).numpy(), 'gray')\n",
    "        plt.axis(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113288\n",
      "53738\n"
     ]
    }
   ],
   "source": [
    "with open('A4_640.npy', 'rb') as f:\n",
    "    A4_PSFs_raw = np.load(f)\n",
    "with open('A6_568.npy', 'rb') as f:\n",
    "    A6_PSFs_raw = np.load(f)\n",
    "\n",
    "print(len(A4_PSFs_raw))\n",
    "print(len(A6_PSFs_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75143 56799 28987 ...  5192 77708 98539]\n",
      "107476\n"
     ]
    }
   ],
   "source": [
    "# Reduce the size of the larger dataset (A4-640)\n",
    "A4_indices = np.random.choice(range(len(A4_PSFs)), len(A6_PSFs))\n",
    "A4_PSFs_reduced = A4_PSFs_raw[A4_indices]\n",
    "\n",
    "# Combine, create labels, and reshuffle all\n",
    "training_data = np.concatenate((A4_PSFs_reduced, A6_PSFs_raw))\n",
    "labels = np.concatenate((np.zeros(len(A4_PSFs_reduced)), np.ones(len(A6_PSFs_raw))))\n",
    "\n",
    "# Split into training, testing, and validation sets\n",
    "training_percent = 0.8\n",
    "testing_percent = 0.1\n",
    "validation_percent = 0.1\n",
    "\n",
    "random_seed = 1 # random seed for reproducibility\n",
    "np.random.seed(random_seed)\n",
    "all_indices = np.random.choice(np.arange(len(training_data)), size=len(training_data), replace=False)\n",
    "print(all_indices)\n",
    "print(len(all_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSFDataset(Dataset):\n",
    "    def __init__(self, train):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model code\n",
    "class CNN(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, channel_widths, pooling, nonlinearity=nn.ReLU()):\n",
    "        super(CNN, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(channel_widths)-2):\n",
    "            # convolution layer\n",
    "            # you can play around with kernel_size, padding, and stride if you like\n",
    "            # kernel_size is most likely to have an impact\n",
    "            # arguments are: Conv2d(n_input_channels, n_output_channels, \n",
    "            #                       filter_side_length, padding, stride_length)\n",
    "            layers.append(nn.Conv2d(channel_widths[i], channel_widths[i+1],\n",
    "                                    kernel_size=5, padding=2, stride=1, bias=False))\n",
    "            layers.append(nonlinearity) # non-linearity\n",
    "        # add final layer\n",
    "        layers.append(nn.Conv2d(channel_widths[-2], channel_widths[-1],\n",
    "                                    kernel_size=5, padding=2, stride=1, bias=False))\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        self.global_pooling = pooling # reduce each of the H x W feature maps to a single pooled value\n",
    "        self.pool_size = pooling.output_size[0]*pooling.output_size[1]\n",
    "        self.linear = nn.Linear(channel_widths[-1]*self.pool_size, 10)  # score each class to obtain logits\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        B = x.size(0) # number of input images\n",
    "        features = self.backbone(x) # get feature maps (B, N_feature_maps, H, W)\n",
    "        pooled_features = self.global_pooling(features) # (B, N_feature_maps, 1, 1)\n",
    "        pooled_features = pooled_features.view(B, -1) # (B, N_feature_maps)\n",
    "        logits = self.linear(pooled_features) # (B, N_classes)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
